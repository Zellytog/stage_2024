\documentclass{article}
\usepackage{prelude}

\title{Choix, réalisabilité et evidenced frames}

\author{Titouan Leclercq}

\date{April 15$^{\mathrm{th}}$ -- July 15$^{\mathrm{th}}$}

\begin{document}

\maketitle

\tableofcontents

\section{Réalisabilité}

L'élément central de ce stage est la réalisabilité. Nous nous devons donc d'en donner une présentation un peu détaillée. Pour cela, nous allons faire un détour légèrement historique en présentant l'idée à l'origine de ce concept.

\subsection{L'interprétation BHK}

L'interprétation de Brouwer-Heying-Kolmogorov (BHK) désigne une interprétation de la sémantique d'une propositions, non en terme de valeurs de vérité, mais en terme d'ensemble de ses preuves.

La volonté derrière l'interprétation BHK est de définir une logique constructiviste, en ce qu'une preuve d'une proposition doit explicitement construire les outils auxquels elle fait appel (en particulier, on cherche à avoir la propriété du témoin, qui dit que si $\vdash \exists x, \varphi$ alors il existe $t$ tel que $\vdash \varphi[t/x]$). Comme le principe du tiers exclu est non constructif, on se place dans le cadre de la logique intuitionniste.

On suppose qu'on a un ensemble de propositions $\Phi$ et un ensemble de témoins, $X$. L'interprétation BHK donne une façon de penser une relation signifiant \textit{être une preuve de}, qu'on notera $x\reali \varphi$~:
\begin{itemize}
\item on suppose qu'on a défini ce que signifie $x\reali\varphi$ pour $\varphi$ atomique
\item on n'a jamais $x\reali \bot$
\item si $\varphi$ est de la forme $\psi\to \chi$, alors $x\reali\psi \to\chi$ signifie que $x$ représente une fonction qui, pour tout $y\reali\psi$, associe $x(y)\reali\chi$. Prouver que $\psi$ implique $\chi$ est donc une fonction qui peut renvoyer une preuve de $\chi$ dès qu'on a une preuve de $\psi$.
\item si $\varphi$ est de la forme $\psi\land\chi$, alors $x\reali \psi\land \chi$ signifie que $x = \langle y,z\rangle$ où $y\reali \psi$ et $z\reali \chi$. Ainsi être une preuve d'une conjonction est une paire de preuves, donnant la preuve de chaque composante.
\item si $\varphi$ est de la forme $\psi\lor\chi$, alors $x\reali\psi\lor \chi$ signifie que $x = \langle i,y\rangle$ où $i\in\{1,2\}$ et, de plus, si $i = 1$ alors $y\reali \psi$ et si $i = 2$ alors $y\reali \chi$. Être une preuve d'une disjonction est donc une preuve d'une des deux propositions, accompagnée de l'information de laquelle des propositions est prouvée (c'est une union disjointe en terme ensembliste).
\item si $\varphi$ est de la forme $\forall a, \psi$ alors $x\reali\forall a, \psi$ signifie que $x$ représente une fonction qui, pour tout $v$, associe $x(a)\reali \psi[v/a]$. Une preuve d'une quantification universelle est ainsi une foncion qui, au terme auquel on veut appliquer la proposition, renvoie une preuve de cette proposition appliquée au terme.
\item si $\varphi$ est de la forme $\exists a, \psi$ alors $x\reali \exists a, \psi$ signifie que $x = \langle t,y\rangle$ où $t$ est un terme et $y\reali \psi[t/a]$. Ainsi, donner une preuve d'une proposition existentielle signifie donner un témoin du caractère existentiel (quel terme est désigné par le $\exists$) et une preuve que ce témoin vérifie effectivement la proposition.
\end{itemize}

On voudrait alors que la relation $\reali\subseteq X \times \Phi$ ainsi construite définisse une théorie
\[\mathcal T_\reali \defeq \{\varphi\in\Phi\mid \exists x \in X, x\reali \varphi\}\]

En fait, on voit que cette théorie est close par les règles de la déduction naturelle intuitionnistes sous quelques hypothèses sur la structure de $X$~:
\begin{itemize}
\item si on suppose qu'on a des preuves de $\varphi_1,\ldots,\varphi_n$ alors on a évidemment une preuve de $\varphi_i$ pour chaque $i\in\{1,\ldots,n\}$, d'où \begin{center}\begin{prooftree}\hypo{\varphi\in\Gamma}\infer1{\Gamma\vdash \varphi}\end{prooftree}\end{center}
\item si dans le contexte $\varphi_1,\ldots,\varphi_n$ on a une preuve de $\bot$, comme il n'y a pas de preuve de $\bot$ alors par principe d'explosion on déduit qu'on a une preuve de n'importe quelle proposition
\item si dans le contexte où on a des preuves de $\Gamma,\varphi$ on peut construire une preuve de $\psi$, alors on peut considérer la fonction, dans le contexte $\Gamma$, qui à une preuve de $\varphi$ associe la preuve de $\psi$ construite, d'où \begin{center}\begin{prooftree}\hypo{\Gamma, \varphi\vdash \psi}\infer1{\Gamma\vdash\varphi\to\psi}\end{prooftree}\end{center}
\item si dans le contexte $\Gamma$ on a une preuve de $\varphi \to \psi$ et une preuve de $\varphi$, comme une preuve de $\varphi\to\psi$ est une fonction, on peut l'appliquer en la preuve de $\varphi$ pour obtenir une preuve de $\psi$, d'où \begin{center}\begin{prooftree}\hypo{\Gamma\vdash \varphi\to\psi}\hypo{\Gamma\vdash\varphi}\infer2{\Gamma\vdash \psi}\end{prooftree}\end{center}
\end{itemize}

On peut faire de même pour $\land$, $\lor$, $\forall$ et $\exists$. Pour pouvoir construire notre interprétation, il nous faut donc un ensemble $X$ muni de structure~:
\begin{itemize}
\item chaque $x\in X$ doit pouvoir se voir comme une forme de fonction dont on peut abstraire les entrées, au sens où si $t\in X$ possède des entrées $a_1,\ldots,a_n$ alors on veut avoir $\lambda a_i. t\in X$ qui est une entrée sur $a_1,\ldots,a_n \setminus a_i$ donnant la fonction $a_i \mapsto t$. En ayant cela, l'introduction et l'élimination de $\to$ devient automatique.
\item on doit être capable de créer des paires $\langle x,y\rangle \in X$ d'éléments de $X$, et des projections pour récupérer les informations sur chaque coordonnée. Dans ce cas l'introduction et l'élimination de $\land$ est directe.
\item on doit pouvoir représenter au moins un ensemble $\{0,1\}$ pour pouvoir définir l'introduction de $\lor$. Pour l'élimination de $\lor$, il nous faut une instruction if / then / else sur cet ensemble $\{0,1\}$ représenté pour faire une disjonction de cas sur la première coordonnée d'une preuve de $\varphi\lor \psi$.
\item on doit pouvoir représenter les termes du premier ordre au sein même de $X$, pour pouvoir considérer une fonction qui à un terme du premier ordre associe un élément de $X$ et avoir des paires dont une coordonnée est un terme du premier ordre.
\end{itemize}

Ces conditions donnent une estimation assez fidèle de ce que l'on va rechercher dans un modèle de réalisabilité. On va maintenant voir le premier exemple de réalisabilité, qui est une interprétation comme on l'a définie ici utilisant les fonctions calculables~: la réalisabilité de Kleene.

\subsection{Réalisabilité de Kleene}

Ce modèle de réalisabilité est en fait le point de départ même de la réalisabilité. Il se base sur le fait que pour raisonner sur les entiers, les fonctions calculables donnent une classe de fonctions largement raisonnable. Cependant, on a vu qu'il fallait, en plus de fonctions, pouvoir internaliser les termes du premier ordre. Heureusement, un théorème de calculabilité nous dit qu'il existe une fonction de codage $\varphi$ qui est surjective dans les fonctions calculables (et prend un entier en paramètre).

On considère donc $X = \bN$, et on peut vérifier que les conditions sont vérifiées~:
\begin{itemize}
\item si $e$ représente une fonction calculable sur $n + m$ entrées, on peut construire un code $e'$ représentant cette fonction calculable sur $n$ entrées dont les autres $m$ entrées ont été abstraites~: c'est le théorème $S_m^n$. De plus, on a une opération d'application d'une fonction calculable à un argument.
\item la bijection de Cantor nous donne une fonction $(n,m) \mapsto \langle n,m\rangle$ calculable dont les projections sont calculables.
\item l'ensemble $\{0,1\}$ est un sous-ensemble de $\bN$, il est donc évident qu'on peut l'utiliser. Pour la construction if / then / else, c'est une construction élémentaire en programmation, et on peut la combiner à l'égalité à $0$ pour obtenir l'élimination de $\lor$.
\item on peut représenter l'entier $n\in \bN$ dans $X$, par $n \in \bN$.
\end{itemize}

On peut donc construire une interprétation de $\bN$ comme un ensemble de preuves pour le langage de l'arithmétique. Il se trouve qu'on obtient alors un modèle de l'arithmétique de Heyting (qui est l'arithmétique de Peano mais dans la logique intuitionniste).

\subsection{Ordre supérieur}

Les conditions décrites plus haut peuvent se simplifier grandement dans le cas où l'on étudie une théorie non pas d'ordre $1$, mais d'ordre $2$ (ou d'ordre supérieur). Présentons succinctement la syntaxe d'une théorie d'ordre $2$ (avec des termes d'ordre 1).

On ajoute un ensemble de variables du second ordre, qu'on notera par des lettres majuscules, chacune ayant une arité. Une variable $X$ d'arité $n$ représente un prédicat à $n$ variables libres quelconque. On construit alors nos propositions comme pour celle du premier ordre, mais en ajoutant la prise en compte (et la quantification) du deuxième ordre~:
\[\varphi,\psi ::= \cdots\mid X(t_1,\ldots,t_n)\mid \forall^2 X, \varphi\mid \exists^2 X, \varphi\]

En fait, on se rend compte qu'il est possible de largement diminuer le nombre de constructeurs pour nos propositions en encodant par exemple $\land$ et $\lor$ à partir de $\to$ et de $\forall^2$. On définit donc simplement
\[\varphi,\psi ::= X(t_1,\ldots,t_n)\mid \varphi\to\psi\mid \forall^1 x, \varphi\mid \forall^2 X, \varphi\]

On donne l'ensemble des encodages qu'on peut alors faire~:
\begin{itemize}
\item $t = u \defeq \forall X, X(t) \to X(u)$
\item $\varphi\land \psi \defeq \forall X, (\varphi \to \psi \to X) \to X$
\item $\varphi \lor \psi \defeq \forall X, (\varphi \to X) \to (\psi \to X) \to X$
\item $\exists x, \varphi \defeq \forall X, (\forall x, \varphi \to X) \to X$
\item $\exists X, \varphi \defeq \forall Y, (\forall X, \varphi \to Y) \to Y$
\end{itemize}

Ainsi, si l'on arrive à avoir une interprétation de l'ordre $2$, il nous suffit seulement d'interpréter $\to$, $\forall^1$ et $\forall^2$. Remarquons que l'interprétation de $\to$ force $X$ à pouvoir internaliser une notion de fonction (avec un procédé d'abstraction et d'application).

\subsection{Intersection et relativisation}

On a vu qu'il était nécessaire de représenter les termes du premier ordre dans $X$, mais ceci peut être évité en changeant notre façon de considérer la quantification universelle. Plutôt que de voir $\forall x, \varphi$ comme une fonction, on peut aussi considérer cela comme une intersection. Dans ce cas, il nous faut pouvoir définir ce que signifie $t\reali\varphi$ avec $x\leftarrow n$ pour un certain $n$, ce qui nous pousse à généraliser notre relation $\reali$ avec des contextes. On notera $t\reali^\sigma \varphi$ pour dire que $t$ est une preuve de $\varphi$ dans le cas où $\sigma$ est utilisé pour interpréter $\varphi$. Dans ce cas, $\sigma$ va associer un entier à chaque variable libre dans $\varphi$. On introduit de même un contexte pour les variables du second ordre qui pourraient être libres dans $\varphi$, qu'on notera $\rho$, et où une variable $X$ d'arité $n$ est associée à une fonction $\bN^n \to \mathcal P(X)$. On notera alors $t\reali_\rho^\sigma \varphi$ pour noter nos deux contextes.

On arrive alors à une définition alternative de $\reali$ considérant les quantifications comme des preuves uniformes~:
\begin{itemize}
\item $t\reali^\sigma \forall x,\varphi \defeq \forall n \in \bN, (t\reali^{\sigma[x \leftarrow n]} \varphi)$
\item $t\reali_\rho \forall X, \varphi \defeq \forall S : \bN \to \mathcal P(X), (t\reali_{\rho[X\leftarrow S]}\varphi)$
\end{itemize}

C'est avant tout cette interprétation du second ordre qu'on considère, où réaliser une quantification signifie réaliser uniformément toutes les instances possibles.

On voit qu'alors il n'est plus nécessaire d'internaliser les notions du premier (ni même du second) ordre, et il nous suffit alors d'avoir un langage dans lequel on peut abstraire et appliquer des fonctions~: il est dur de ne pas penser au $\lambda$-calcul dans ce contexte, mais nous y reviendrons plus tard.

Il reste cependant souhaitable de pouvoir considérer le $\forall$ comme fonctionnel. En effet, il y a des cas dans lesquels realiser $\varphi(x)$ demande explicitement de savoir de quel $x$ on parle, et le réaliseur peut dépendre directement de ce $x$. L'avantage de l'interprétation uniforme est qu'elle permet de récupérer cela dans un deuxième temps~: il suffit de construire un prédicat dont l'utilité est de récupérer le $x$ que l'on veut. Dans le cas des entiers, on peut construire un prédicat $\bN(x)$ tel que $n\reali_\rho^\sigma\bN(x)$ exactement quand $x$ est interprété dans $\sigma$ par $n$. Dans ce cas, écrire $\forall x, \bN(x) \implies \varphi$ nous dit exactement que pour n'importe quel $n$, obtenir l'information de ce $n$ permet de prouver $\varphi$.

On a donc deux sortes de quantifications~: les quantifications uniformes et les quantification relativisées, l'une considérant l'intersection et l'autre l'espace fonctionnel.

En fait, on verra que la notion de relativisation peut se voir comme un cas particulier d'une construction catégorique plus générale (la construction \textit{tripos to topos} dans le cas d'un tripos de réalisabilité).

\subsection{Lambda-calcul et saturation}

On a mentionné plus tôt qu'il était naturel, dans le contexte donné, de considérer le $\lambda$-calcul comme candidat pour faire un modèle de réalisabilité. En reprenant ce qui a été dit plus tôt, en considérant comme langage l'arithmétique du second ordre, on définit donc une interprétation en utilisant pour $X$ l'ensemble $\Lambda$ des $\lambda$-termes, engendré par
\[t,u ::= x\mid \lambda x. t\mid t\;u\]

On donne donc une première tentative de définition de $t\reali_\rho^\sigma \varphi$ où $\rho$ associe toute variable libre du premier ordre de $\varphi$ à une fonction $\bN^n \to \mathcal P(\Lambda)$ et $\sigma$ associe toute variable libre du premier ordre de $\varphi$ à un entier $n \in \bN$. On utilisera la notation $\trad\varphi_\rho^\sigma \defeq \{t\in\Lambda\mid t \reali_\rho^\sigma \varphi\}$~:
\begin{itemize}
\item $\trad{X(t_1,\ldots,t_n)}_\rho^\sigma \defeq \rho(X)(t_1^\sigma,\ldots,t_n^\sigma)$
\item $\trad{\varphi \to \psi}_\rho^\sigma\defeq \{t\in \Lambda \mid \forall u\reali_\rho^\sigma \varphi, t\;u\reali_\rho^\sigma \psi\}$
\item $\trad{\forall x, \varphi}_\rho^\sigma \defeq \bigcap_{n \in \bN}\trad\varphi_\rho^{\sigma[x\leftarrow n]}$
\item $\trad{\forall X, \varphi}_\rho^\sigma \defeq \bigcap_{S : \bN^n \to \mathcal P(\Lambda)}\trad\varphi_{\rho[X\leftarrow S]}^\sigma$
\end{itemize}

Tout semble bien fonctionner, mais il y a en fait un problème~: notre interprétation précédente considérait $X$ comme un objet sémantique et non syntaxique. On entend par cela que dans $\Lambda$, il y a une différence entre $(\lambda x.t)u$ et $t[u/x]$ qui sont des termes différents, mais sont dans la même classe de $\Lambda/=_\beta$. On pourrait donc décider de ne considérer non pas $\Lambda$ mais $\Lambda/=_\beta$, mais il existe une façon plus élégante de régler ce problème.

L'endroit où cette distinction apparait est dans la preuve que les règles de la déduction naturelle intuitionniste sont vérifiées par notre interprétation de réalisabilité, plus précisément dans la règle d'introduction de $\to$. En considérant un système de types associant une proposition à un terme, de la forme $x_1 : \varphi_1,\ldots,x_n : \varphi_n \vdash t : \varphi$. Dans ce cas, la validité d'un tel séquent est
\[t_1\reali_\rho^\sigma \varphi_1,\ldots,t_n \reali_\rho^\sigma \varphi_n \implies t^{x_1 \leftarrow t_1,\ldots, x_n\leftarrow t_n}\reali_\rho^\sigma \varphi\]
et on peut réécrire $\to_\mathrm i$ par la règle
\begin{center}
  \begin{prooftree}
    \hypo{\Gamma, x : \varphi\vdash t : \psi}
    \infer1{\Gamma\vdash \lambda x.t : \varphi \to \psi}
  \end{prooftree}
\end{center}

On veut donc unifier d'un côté $t^{x_1\leftarrow t_1,\ldots,x_n\leftarrow t_n, x\leftarrow u}$ et $(\lambda x.t^{x_1\leftarrow t_1,\ldots,x_n\leftarrow t_n})u$, ce qui (à des questions d'$\alpha$-conversion près) est une antéréduction~: le second terme se réduit en le premier terme.

Ainsi la validité de cette règle a besoin d'un élément supplémentaire qui peut être satisfait par la condition suivante~: il faut qu'à chaque $\varphi$, si $t\reduc u$ et $u\reali \varphi$ alors $t\reali \varphi$. En fait, on peut montrer qu'il suffit pour cela d'assurer cette condition sur les $\rho(X)$. Donnons donc un peu de vocabulaire.

\begin{defi}[Partie saturée]
  Soit $S\subseteq\Lambda$, on dit que $S$ est saturée si la propriété suivante est vérifiée~:
  \[\forall t,u\in\Lambda, u \in S \land t \reduc u \implies t \in S\]

  On note
  \[\SAT \defeq \{S\subseteq \Lambda\mid S\;\text{est saturée}\}\]
\end{defi}

\begin{lem}
  $(\SAT,\subseteq,\Lambda,\varnothing,\bigcap,\bigcup)$ est un treillis complet.
\end{lem}

\begin{proof}
  Il est évident que $S\in \SAT \implies \varnothing\subseteq S \subseteq \Lambda$ et que ces deux parties sont stables par anté-réduction. Supposons que $\{S_i\}_{i\in I}$ est une famille de parties saturées. Si $t\reduc u$ et $u \in \bigcap S_i$, alors pour tout $i \in I$, $t \in S_i$ par saturation de $S_i$, donc $t\in \bigcap S_i$, donc $\bigcap S_i$ est saturée. De même si $u \in \bigcup S_i$, alors on trouve $i$ tel que $u \in S_i$ donc $t\in S_i$ par saturation. Donc $\bigcup S_i$ est saturée. Ainsi $(\SAT,\subseteq,\Lambda,\varnothing, \bigcap,\bigcup)$ est un treillis complet.
\end{proof}

On décide maintenant de modifier l'interprétation au-dessus en disant juste que $\rho(X) : \bN^n \to \SAT$, et de même que l'intersection pour le $\forall X, \varphi$ est définie sur $S : \bN^n \to \SAT$. On peut alors montrer le lemme de saturation.

\begin{lem}[Saturation]
  Pour toute formule $\varphi$, $\trad\varphi_\rho^\sigma\in \SAT$.
\end{lem}

\begin{proof}
  On procède par induction sur $\varphi$~:
  \begin{itemize}
  \item si $\varphi = X(t_1,\ldots,t_n)$ alors $\trad\varphi_\rho^\sigma=\rho(X)(t_1^\sigma,\ldots,t_n^\sigma)\in \SAT$.
  \item si $\varphi = \psi \to \chi$, supposons que $t\reali_\rho^\sigma \psi \to \chi$, $t'\reduc t$ et $u\reali_\rho^\sigma\psi$. Par hypothèse, $t\;u\reali_\rho^\sigma \chi$, et comme par hypothèse d'induction $\trad\chi_\rho^\sigma\in\SAT$ et $t'\;u\reduc t\;u$, on en déduit que $t'\;u\reali_\rho^\sigma \chi$. Ainsi pour tout $u\reali_\rho^\sigma\psi$, $t'\;u\reali_\rho^\sigma\chi$, ce qui signifie que $t'\reali_\rho^\sigma\psi\to\chi$.
  \item les deux interprétations données par des intersections donnent des ensembles saturés car $\SAT$ est un treillis complet.
  \end{itemize}
  Donc par induction $\trad\varphi_\rho^\sigma\in\SAT$.
\end{proof}

On peut alors déduire le lemme d'adéquation (on le montrera plus tard pour une version enrichie du $\lambda$-calcul).

\subsection{Conclusion sur la réalisabilité}

Notre situation de base pour la réalisabilité est donc de pouvoir construire des théories cohérentes sur l'arithmétique du second ordre, en se basant sur un $\lambda$-calcul. On verra plus tard que les effets qu'on ajoute à notre $\lambda$-calcul peuvent grandement changer la théorie engendrée.

\section{Mathématiques à rebours}

L'autre part importante de ce stage se trouve dans les mathématiques à rebours. Par mathématiques à rebours, on désigne un domaine, lié à la calculabilité, dont l'objectif est de quantifier la force logique des théorèmes usuels des mathématiques. Nous allons donc présenter les éléments importants de ce domaine qui sont utilisés dans le stage.

\subsection{Présentation globale}

La première question à se poser, pour organiser les théorèmes suivant leur force logique, est \textit{comment peut-on décider si un théorème est plus fort qu'un autre ?} Il est assez clair qu'on s'attend à un pré-ordre tout sauf total (mais à un pré-ordre quand même). L'idée la plus simple est de dire que $\varphi$ est un théorème plus fort que $\psi$ si $\varphi \vdash \psi$, donc si $\varphi$ est une proposition plus faible pour l'ordre de prouvabilité que $\psi$ (c'est assez logique~: être un théorème très fort, c'est être un théorème dont la preuve implique un maximum de choses). Le souci, maintenant, est que si on considère pour $\vdash$ la relation de prouvabilité dans $\ZF$, alors la plupart des résultats sont vrais. On conviendra que le pré-ordre $(\{*\},=)$ n'est pas le plus intéressant, il nous faut donc quelque chose de plus précis.

Si un théorème fort est un théorème qui entraine plus de résultats avec sa vérité, et comme une théorie est un ensemble de résultats pris pour axiomes, on peut donc s'attendre à ce qu'une théorie plus faible prouve moins de résultats directement, et laisse donc plus de marge pour séparer des résultats. Cependant, la théorie doit être suffisamment forte pour rester expressive, et prouver ce qu'on considère comme le plus élémentaire. Par exemple dire que l'addition est commutative dans $\bN$ n'est pas un résultat qu'on souhaite placer dans notre ordre.

Le choix se porte alors sur l'arithmétique du second ordre, plus précisément sur un sous-système appelé RCA$_0$. Ce sous-système contient suffisamment pour parler des réels et des fonctions continues (même des fonctions mesurables). C'est donc un système très expressif, relativement à sa faible capacité à prouver des résultats.

\subsection{Le cas intuitionniste et l'indépendance relative}

Comme on l'a dit, plus la théorie de base est faible, plus on est précis dans le pré-ordre intuitif de la force logique. Malheureusement, ça n'est pas toujours ce que l'on souhaite. Par exemple, l'une des questions de théorie des ensembles les plus importantes de l'histoire a porté sur un résultat indépendant de ZFC, l'hypothèse du continu. Dans ce cas, prouver que le résultat est indépendant de ZFC est un meilleur résultat que celui que l'hypothèse du continu est indépendant de ZF.

Syntaxiquement, cela se voit par le fait qu'une preuve de l'hypothèse du continu dans ZFC pourrait se formuler dans ZF, donc l'un implique l'autre. Sémantiquement, cela signifie qu'on peut trouver un modèle validant HC et un validant $\lnot$HC dans une classe de modèles encore plus restreinte que celle des modèles de ZF~: celle des modèles de ZFC. Dans les deux cas, on comprend qu'une théorie plus forte donne un meilleur résultat d'indépendance.

Dans le cas intuitionniste, cette volonté de prouver des cas d'indépendance est récurrente, et il est donc bon de se placer dans un cadre plus fort. En particulier, la version intuitionniste de ZF (pas de ZFC, car le tiers exclu est vrai dans ZFC) nous donne de meilleurs résultats d'indépendance.

\subsection{Les formes faibles de l'axiome du choix}

L'axiome du choix, connu pour être un axiome indépendant de ZF et pour avoir été débattu dans le choix de l'accepter ou non (en raison par exemple de son caractère non constructif), peut se décliner en beaucoup de version faibles. Nous allons en présenter plusieurs, dans l'ordre croissant de leur force logique en logique classique~:
\begin{itemize}
\item \textit{Fan Theorem} (FT)~: supposons qu'on ait un prédicat $P$ sur $\bN^*$ qui est clos par extension, c'est-à-dire que si $u\in P$ et $u \preceq v$ alors $v\in P$. Supposons que pour tout chemin infini $\alpha\in\bN^\bN$ il existe un nombre $n$ tel que $\alpha_{0,\ldots,n}\in P$, alors il existe $n \in\bN$ tel que pour tout $\alpha \in \bN^\bN$, $\alpha_{0,\ldots,n}\in P$.
\item \textit{Weak König's Lemma} (WKL)~: tout arbre binaire infini possède une branche infinie.
\item \textit{König's Lemma} (KL)~: tout arbre infini mais finiment branchant (pour tout n\oe ud il existe un nombre fini de n\oe uds qui en sont voisins) possède une branche infinie.
\item \textit{Axiome du choix dénombrable} (ACN)~: pour toute famille $(X_i)_{i\in \bN}$ d'ensembles non vides, il existe une fonction $\alpha : \bN \to \bigcup X_i$ telle que $\alpha(i)\in X_i$.
\item \textit{Axiome du choix dépendant} (DC)~: soit un ensemble $X$ et une relation binaire $R$ sur $X$ telle que pour tout $x\in X$, il existe $y\in X$ tel que $R(x,y)$, alors il existe une suite $\alpha : \bN \to X$ telle que $\forall i\in \bN, R(\alpha(i),\alpha(i+1))$.
\item \textit{Axiome du choix} (AC)~: toute surjection admet une section.
\end{itemize}

On sait que dans le cas classique, cette hiérarchie est strictement croissante. Dans le cas intuitionniste, plus faible, la hiérarchie est donc encore stricte. Par contre, elle n'est pas croissante, puisqu'on peut par exemple avoir DC sans avoir KL.

En fait, on peut distinguer deux principes importants dans les premières versions~: l'omniscience et le choix. Dans le cas de DC, on peut construire notre suite simplement en considérant la suite jusqu'à un rang $n$ et en appliquant un oracle permettant de trouver un élément en relation avec le dernier construit. On passe donc simplement d'une fonction locale à une fonction globale par itération. Dans le cas de KL, il nous faut traiter l'infinité de données des chemins potentiels pour trouver le sommet suivant dans le chemin, en pouvant savoir à l'avance de quel côté se trouve un chemin infini. En logique classique, l'omniscience est toujours vérifiée, mais pas en intuitionniste, d'où cette cassure de monotonie au passage de KL à ACN.

\section{Plus de généralité pour la réalisabilité}

Nous avons abordé pour l'instant la réalisabilité sous un angle assez empirique~: étant donné un $\lambda$-calcul, on peut essayer en vérifiant des conditions assez intuitives de construire un modèle de réalisabilité, et de voir la théorie en résultant. Prendre une approche plus systématique et abstraire le système de calcul en lui-même va nous permettre d'aller plus loin que cet empirisme.

\subsection{Les effets sont logiques}

Une branche importante de la réalisabilité, la réalisabilité à le Krivine (ou réalisabilité classique), naît de l'observation que l'instruction call/cc, qui est une instruction de programmation permettant par exemple d'utiliser des exceptions, peut être typée par la loi de Peirce, principe équivalent au tiers exclu. Comme les exceptions permettent en quelque sorte de revenir en arrière dans l'exécution d'un programme, ce typage donne alors à penser que la capacité de revenir en arrière permet de passer de la logique intuitionniste à la logique classique. On peut aussi voir ça en terme de jeux en considérant que la logique intuitionniste demande à un défendant de gagner face à une série de contradictions en étant toujours cohérent avec lui-même, là où la logique classique premet au défendant de changer d'avis sur un argument en redéfendant cet argument du début.

Cela illustre un principe central de la réalisabilité~: ajouter des effets au langage de programmation donne dans le modèle de réalisabilité des formules logiques qui peuvent devenir vraies. Jean-Louis Krivine a alors pu utiliser ce typage pour construire une version de la réalisabilité dans laquelle la théorie $\mathcal T_\reali$ est une théorie classique.

On peut donc naturellement se demander comment classer les effets selon les théorèmes qui en découlent. Pour cela, il devient important de trouver un cadre plus uniforme pour aborder la réalisabilité, puisqu'il est difficile de traiter d'abstraction sans le faire dans un cadre défini. Le cadre trouvé dans le cas de la réalisabilité est celui des catégories.

\subsection{Tripos de réalisabilité}

Les catégories nous permettent d'étudier la logique, en particulier avec la notion de catégorie fibrée. Celle-ci permet de définir la notion d'avoir deux catégories où l'une exprime un langage parlant de l'autre catégorie, ou de construire une famille de catégories indicée par une autre catégorie.

Dans le cas de la pur logique propositionnelle (intuitionniste), la structure algébrique associée est celle des pré-algèbres de Heyting, qui correspond catégoriquement aux catégories ordonnées cartésiennes fermées. Pour en faire de la logique parlant plus explicitement d'une certaine catégorie (disons des ensembles), on considère une fibration au-dessus de cette catégorie, dont les fibres sont des pré-algèbres de Heyting.

Un tripos est une telle structure~: c'est une paire de catégories et un foncteur $p : \mathbb E \to \mathbb B$ de telle sorte que la fibration catégorique résultante vérifie des propriétés de cohérence permettant de faire de la logique du premier ordre et d'ordre supérieur.

Un tripos peut en fait être construit pour tout langage respectant certaines propriétés, on l'appelle le tripos de réalisabilité.

\section{Boîte à outils réalisable}

\subsection{Un modèle de HA2 amélioré}

On commence par donner une présentation d'une version enrichie de l'arithmétique de Heyting du second ordre (HA2) avec un modèle de réalisabilité basé sur le lambda-calcul.

\subsubsection{Langage de programmation}

Le $\lambda$-calcul est connu pour permettre de représenter n'importe quelle fonction calculable. A ce titre, on pourrait considérer le $\lambda$-calcul pur non typé pour réaliser des propositions. Cependant, pour la même raison, nous allons adopter un $\lambda$-calcul possédant plus de constructeurs~: tant qu'à pouvoir coder tout ce que l'on souhaite, autant se donner directement des primitives pour manipuler les éléments qui nous importent.

\begin{defi}[$\Lambda$]
  On se donne un ensemble $\mathcal X_\Lambda$ de variables de termes. On définit l'ensemble des $\lambda$-termes, $\Lambda$, par la grammaire suivante~:
  \[t,u ::= x\mid\lambda x. t\mid t\;u\mid \langle t,u\rangle\mid \pi_1\;t\mid \pi_2\;t\mid \bZ\mid \bfS\;t\mid \rec_\bN\;t\;u\;u\mid \btt\mid\bff\mid\rec_\bB\;t\;u\;v\mid [\;]\mid t:: u\mid \rec_\bL\;t\;u\;v\]
\end{defi}

\begin{defi}[Contexte]
  On définit l'ensemble $\Lambda_{\bnnbr{\;}}$ des contextes, définit récursivement par~:
  \begin{multline*}
    E,F::= \bnnbr{\ }\mid \lambda x.E\mid E\;t\mid t\;E\mid \langle E,t\rangle\mid \langle t,E\rangle\mid \pi_1\;E\mid\pi_2\;E\mid\bfS\;\mid \rec_\bN\;E\;t\;u\mid \rec_\bN\;t\;E\;u\mid\rec_\bN\;t\;u\;E\\\mid\rec_\bB\;E\;t\;u\mid\rec_\bB\;t\;E\;u\mid\rec_\bB\;t\;u\;E\mid E::t\mid t::E\mid \rec_\bL\;E\;t\;u\mid \rec_\bL\;t\;E\;u\mid\rec_\bL\;t\;u\;E
  \end{multline*}

  Si $C$ est un contexte et $t$ un $\lambda$-terme, on note $C\bnnbr{t}$ le terme obtenu en substituant $\bnnbr{}$ par $t$ dans l'écriture de $C$.
\end{defi}

On définit de façon usuelle la substitution ainsi que la relation d'$\alpha$-équivalence, modulo laquelle on travaillera à partir de maintenant.

\begin{defi}[Réduction]
  On définit la relation $\mapsto\subseteq \Lambda\times\Lambda$ par les règles suivantes~:
  \begin{center}
    \begin{prooftree}
      \infer0{(\lambda x.t)u\mapsto t[u/x]}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \infer0{\forall i\in\{1,2\}, \pi_1\;\langle t_1,t_2\rangle \mapsto t_i}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \infer0{\rec_\bN\;t\;u\;\bZ\mapsto t}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \infer0{\rec_\bN\;t\;u\;(\bfS\;v)\mapsto u\;v\;(\rec_\bN\;t\;u\;v)}
    \end{prooftree}

    \vspace{0.5cm}
    
    \begin{prooftree}
      \infer0{\rec_\bB\;t\;u\;\btt\mapsto t}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \infer0{\rec_\bB\;t\;u\;\bff\mapsto u}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \infer0{\rec_\bL\;t\;u\;[\;]\mapsto t}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \infer0{\rec_\bL\;t\;u\;(v::w)\mapsto u\:v\:w\:(\rec_\bL\:t\:u\:w)}
    \end{prooftree}
  \end{center}

  On définit alors la relation $\reduc$ par
  \[t\reduc u \defeq \exists C \in\Lambda_{\bnnbr{\;}},\exists t'\;u'\in\Lambda, t = C\bnnbr{t'}\land u = C\bnnbr{u'}\land t' \mapsto u'\]
\end{defi}

On introduit la notion d'ensemble saturé, qui peut se considérer comme une partie de $\Lambda$ qui est calculatoirement pertinente.

\begin{defi}[Partie saturée]
  Soit $S\subseteq\Lambda$, on dit que $S$ est saturée si la propriété suivante est vérifiée~:
  \[\forall t,u\in\Lambda, u \in S \land t \reduc u \implies t \in S\]

  On note
  \[\SAT \defeq \{S\subseteq \Lambda\mid S\;\text{est saturée}\}\]
\end{defi}

\subsubsection{Partie logique}

On définit maintenant la partie logique de notre modèle de réalisabilité. Celui-ci est un modèle multi-sorté, qui comporte les trois sortes $\{\bN,\bB,\bL\}$ représentant respectivement les entiers, les booléens et les listes d'entiers. On se donne la signature suivante pour construire nos termes du premier ordre (où l'exposant indique l'arité des fonctions)~:
\[\mathcal L \defeq \{0^\bN, S^{\bN\to\bN}, +^{\bN\to\bN\to\bN}, \times^{\bN\to\bN\to\bN}, \btt^\bB, \bff^\bB, [\:]^\bL, ::^{\bL\to\bL\to\bL}\}\]

\begin{defi}[Termes du premier ordre]
  On se donne un ensemble dénombrable $\mathcal X_1$ de variables du premier ordre. Un contexte de typage du premier ordre $\Gamma$ est une liste de paires $(x,\tau)\in \mathcal X_1\times \{\bN,\bB,\bL\}$. On définit l'ensemble des termes du premier ordre bien typés par les règles suivantes~:
  \begin{center}
    \begin{prooftree}
      \infer0{\Gamma\vdash 0 : \bN}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\vdash \bt : \bN}
      \infer1{\Gamma\vdash S\;\bt : \bN}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\vdash \bt : \bN}
      \hypo{\Gamma\vdash \bu : \bN}
      \infer2{\Gamma\vdash \bt + \bu : \bN}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\vdash \bt : \bN}
      \hypo{\Gamma\vdash \bu : \bN}
      \infer2{\Gamma\vdash \bt \times \bu : \bN}
    \end{prooftree}

    \vspace{0.5cm}

    \begin{prooftree}
      \infer0{\Gamma\vdash \btt : \bB}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \infer0{\Gamma\vdash \bff : \bB}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \infer0{\Gamma\vdash [\:] : \bL}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\vdash \bt : \bN}
      \hypo{\Gamma\vdash \bu : \bL}
      \infer2{\Gamma\vdash \bt :: \bu : \bL}
    \end{prooftree}
  \end{center}
\end{defi}

On peut maintenant définit les formules de notre HA2 enrichi.

\begin{defi}[Propositions]
  On se donne un ensemble $\mathcal X_2$ de variables du second ordre. Un contexte de typage du second ordre $\Delta$ est une liste de paires $(X,\alpha) \in \mathcal X_2\times \List(\{\bN,\bB,\bL\})$. Une proposition du second ordre est un objet bien typé par les règles suivantes~:
  \begin{center}
    \begin{prooftree}
      \hypo{(X : A_1,A_2,\ldots,A_n)\in\Delta}
      \hypo{\forall i \in \{1,\ldots,n\}, \Gamma\vdash \bt_i : A_i}
      \infer2{\Gamma\mid\Delta\vdash X(\bt_1,\ldots,\bt_n) : \Propo}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\vdash \varphi : \Propo}
      \hypo{\Gamma\mid\Delta\vdash \psi : \Propo}
      \infer2{\Gamma\mid\Delta\vdash \varphi \land \psi : \Propo}
    \end{prooftree}

    \vspace{0.5cm}
    
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\vdash \varphi : \Propo}
      \hypo{\Gamma\mid\Delta\vdash \psi : \Propo}
      \infer2{\Gamma\mid\Delta\vdash \varphi \to \psi : \Propo}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma, x : A\mid \Delta\vdash \varphi : \Propo}
      \infer1{\Gamma\mid\Delta\vdash\forall x^A, \varphi : \Propo}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\mid \Delta, X : A_1,\ldots,A_n\vdash \varphi : \Propo}
      \infer1{\Gamma\mid\Delta\vdash \forall X^{A_1,\ldots,A_n}, \varphi : \Propo}
    \end{prooftree}

    \vspace{0.5cm}

    \begin{prooftree}
      \hypo{\Gamma\vdash \bt : \bN}
      \infer1{\Gamma\mid\Delta \vdash \mathbb \bN(\bt) : \Propo}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\vdash \bt : \bB}
      \infer1{\Gamma\mid\Delta \vdash \mathbb \bB(\bt) : \Propo}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\vdash \bt : \bL}
      \infer1{\Gamma\mid\Delta \vdash \mathbb \bL(\bt) : \Propo}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma, x_1 : A_1, \ldots, x_n : A_n\mid\Delta\vdash \varphi : \Propo}
      \infer1{\Gamma\mid\Delta\vdash \Dec(\varphi^{A_1,\ldots,A_n}) : \Propo}
    \end{prooftree}
  \end{center}
\end{defi}

L'idée des prédicats de la forme $\mathbb A(\bt)$ avec une sorte $\mathbb A$ est de donner un témoin du fait que le terme est un terme standard. Le prédicat $\Dec(\varphi)$, lui, exprime qu'un prédicat est décidable. Il permettra de récupérer un témoin de la procédure de décision de l'appartenance à la partie des termes définie par le prédicat.

\begin{nota}
  Pour rendre les propositions plus lisibles, on adoptera la convention que, plutôt que d'écrire $\forall x^A, \mathbb A(x) \to \varphi$, on notera directement $\forall x^{\{A\}}, \varphi$. De même $\forall X^{\{A_1,\ldots,A_n\}}, \varphi$ est une abréviation pour la formule $\forall X^{A_1,\ldots,A_n},\Dec(X^{A_1\ldots,A_n})\to \varphi$. Ce procédé de conditionner par $\mathbb A(x)$ (respectivement $\Dec$) sera appelé ici relativisation. On définit de même la version relativisée de $\exists$.
\end{nota}

\subsubsection{Relation de réalisabilité}

Pour définir la relation de réalisabilité à proprement parler, on va d'abord donner quelques points. Tout d'abord, on peut donner une représentation de chaque terme typé par un $\lambda$-terme, nous noterons $\overline \bt$ le représentant, donné par~:
\begin{itemize}
\item $\overline 0 = \bZ$
\item $\overline{n + 1} = \bfS\;\overline n$
\item $\overline \btt = \btt$
\item $\overline \bff = \bff$
\item $\overline [\:] = [\:]$
\item $\overline{\bt:: \bu} = \overline{\bt} :: \overline{\bu}$
\end{itemize}

On définit aussi les notions de valuations du premier et du second ordre.

\begin{defi}[Valuation]
  Une valuation du premier ordre est une fonction $\sigma : \mathcal X_1 \to \bN\cup \bB\cup\bL$ partielle. On dit que $\sigma$ est adéquate pour un terme $\bt$ si pour toute variable libre $\bx\in \varlib{\bt}$, le type de $\bx$ correspond au type de $\sigma(\bx)$. Si $\sigma$ est adéquate pour $\bt$ alors on note $\bt^\sigma \in \bN\cup\bB\cup\bL$ la valeur obtenue en substituant les variables libres par les valeurs données par $\sigma$. On considère dans la suite que toutes les valuations du premier ordre considérées sont adéquates. De même $\sigma$ est adéquate pour une proposition $\varphi$ si elle est adéquate pour tout terme apparaissant dans $\varphi$.

  Une valuation du second ordre est une fonction $\rho : \mathcal X_2\to \SAT^{\List(\bN\cup\bB\cup\bL)}$. On dit que $\rho$ est adéquate pour une proposition $\varphi$ si pour toute variable libre $X\in\varlib{\varphi}$, l'arité de $\rho(X)$ correspond à celle de $X$.
\end{defi}

On peut maintenant définir la fonction $\trad{-}_\rho^\sigma : \Propo \to \mathcal P(\Lambda)$.

\begin{defi}[Interprétation]
  On définit la fonction par induction, en considérant $\rho$ et $\sigma$ adéquates~:
  \begin{itemize}
  \item $\trad{X(\bt_1,\ldots,\bt_n)}_\rho^\sigma \defeq \rho(X)(t_1^\sigma,\ldots,t_n^\sigma)$
  \item $\trad{\varphi\to\psi}_\rho^\sigma\defeq \{t\in\Lambda\mid \forall u \in \trad{\varphi}_\rho^\sigma, t\;u\in\trad{\psi}_\rho^\sigma\}$
  \item $\trad{\varphi\land \psi}_\rho^\sigma \defeq \{t\in \Lambda\mid \pi_1\;t\in\trad{\varphi}_\rho^\sigma, \pi_2\;t\in\trad{\psi}_\rho^\sigma\}$
  \item $\displaystyle\trad{\forall x^A, \varphi}_\rho^\sigma \defeq \bigcap_{v \in A}\trad{\varphi}_\rho^{\sigma[x \leftarrow v]}$
  \item $\displaystyle\trad{\forall X^{A_1,\ldots,A_n}, \varphi}_\rho^\sigma\defeq\bigcap_{S : \prod_i A_i \to \SAT}\trad{\varphi}_{\rho[X \leftarrow S]}^\sigma$
  \item $\trad{\mathbb A(\bt)}_\rho^\sigma \defeq \{t\in \Lambda\mid t \reduc^* \overline{\bt^\sigma}\}$
  \item \begin{multline*}
    \trad{\Dec(\varphi^{A_1,\ldots,A_n})}_\rho^\sigma \defeq \{t\in \Lambda\mid
    \forall (v_1,\ldots,v_n)\in \mathbb A_1\times\ldots\times\mathbb A_n, \\
    \trad{\varphi}_\rho^{\sigma[\bx_i \leftarrow v_i]}\neq \varnothing \implies t\;\overline{v_1}\;\ldots\;\overline{v_n}\reduc^* \btt\text{ et }\trad{\varphi}_\rho^{\sigma[\bx_i \leftarrow v_i]}=\varnothing \implies t\:\overline{v_1}\;\ldots\;\overline{v_n}\reduc^* \bff\}
  \end{multline*}
  \end{itemize}
\end{defi}

\begin{nota}
  On notera $t\reali_\rho^\sigma \varphi$ pour $t\in\trad\varphi_\rho^\sigma$, et $t\reali\varphi$ pour $t\in\trad\varphi_\varnothing^\varnothing$. On appellera alors $t$ un réaliseur de $\varphi$.
\end{nota}

On peut alors voir la différence fondamentale entre $\forall x^A, \varphi$ et $\forall x^{\{A\}}, \varphi$~: le premier signifie simplement qu'il existe un réaliseur de $\varphi$ qui est uniforme pour $x$, c'est-à-dire que ce même réaliseur fonctionne pour toutes les valeurs possibles de $x$ ; le second, lui, indique que l'on possède une façon de calculer $\overline \bt$ en un réaliseur de $\varphi$. Par exemple $\forall x^\bN, x = x$ signifie qu'il existe $t$ qui réalise chaque $n = n$ pour $n\in \bN$, quand $\forall x^{\{\bN\}}, x = x$ signifie qu'il existe une fonction qui à $\overline n$ associe une preuve de $n = n$. Créer cette distinction permet de contrôler le plus finement possible ce qui est du ressort du calcul et ce qui est du ressort de la vérité logique. En particulier, on voit qu'un réaliseur d'une formule de la forme $\forall x^{\{A\}}, \exists y^{\{B\}}, \varphi(x,y)$ calcule directement une fonction $A \to B$ ainsi qu'une preuve de $\varphi(x,f(x))$, là où sans cette relativisation le $y$ dépendant de $x$ n'a pas besoin d'être calculable et peut simplement exister dans la méta-théorie.

Un des lemmes principaux est celui de saturation, qui assure que tous les ensembles ainsi définis restent saturés.

On commence par montrer que $\SAT$ est un treillis complet.

\begin{lem}
  $(\SAT,\subseteq,\Lambda,\varnothing,\bigcap,\bigcup)$ est un treillis complet.
\end{lem}

\begin{proof}
  Il est évident que $S\in \SAT \implies \varnothing\subseteq S \subseteq \Lambda$ et que ces deux parties sont stables par anté-réduction. Supposons que $\{S_i\}_{i\in I}$ est une famille de parties saturées. Si $t\reduc u$ et $u \in \bigcap S_i$, alors pour tout $i \in I$, $t \in S_i$ par saturation de $S_i$, donc $t\in \bigcap S_i$, donc $\bigcap S_i$ est saturée. De même si $u \in \bigcup S_i$, alors on trouve $i$ tel que $u \in S_i$ donc $t\in S_i$ par saturation. Donc $\bigcup S_i$ est saturée. Ainsi $(\SAT,\subseteq,\Lambda,\varnothing, \bigcap,\bigcup)$ est un treillis complet.
\end{proof}

\begin{lem}[Saturation]
  Pour toute proposition $\varphi \in \Propo$ et valuations $\sigma,\rho$ adéquates, $\trad\varphi_\rho^\sigma\in\SAT$.
\end{lem}

\begin{proof}
  On procède par induction sur $\varphi$~:
  \begin{itemize}
  \item dans le cas de $X(\bt_1,\ldots,\bt_n)$ la définition même de $\trad-_\rho^\sigma$ nous donne un ensemble saturé.
  \item supposons que $\trad{\varphi}_\rho^\sigma\in\SAT$ et $\trad{\psi}_\rho^\sigma\in \SAT$. Soient alors $t,u\in\Lambda$ tels que $t\reduc u$ et $u \reali_\rho^\sigma \varphi \to \psi$. Soit $v\reali_\rho^\sigma\varphi$, par définition on en déduit que $u\;v\reali_\rho^\sigma \psi$ donc par hypothèse d'induction, et comme $t\;v\reduc u\;v$, $t\;v\reali_\rho^\sigma\psi$ donc $t\reali_\rho^\sigma\psi$, d'où $\trad{\varphi\to\psi}_\rho^\sigma \in\SAT$.
  \item supposons que $\trad{\varphi_1}_\rho^\sigma$ et $\trad{\varphi_2}_\rho^\sigma$ sont des ensembles saturés, soient alors $t, u \in \Lambda$ tels que $t\reduc u$ et $u \in \trad{\varphi_1\land \varphi_2}_\rho^\sigma$. On sait donc que pour tout $i\in\{1,2\}$, $\pi_i\;u \reali_\rho^\sigma \varphi_i$ et $\pi_i\;t\reduc\pi_i\;u$, donc par hypothèse d'induction et saturation $\pi_i\;t\reali_\rho^\sigma\varphi_i$. Donc $\trad{\varphi_1\land\varphi_2}_\rho^\sigma\in\SAT$.
  \item Si tous les $\trad\varphi_\rho^{\sigma[x\leftarrow v]}$ sont saturés, comme $\SAT$ est un treillis complet, on en déduit directement que $\bigcap \trad\varphi_\rho^{\sigma[x\leftarrow v]}$ est saturé.
  \item De même que précédemment, le fait que $\SAT$ est un treillis complet assure que ce cas passe à l'induction.
  \item Si $t\reduc u$ et $u\reduc^* \overline{\bt^\sigma}$ alors $t\reduc^*\overline{\bt^\sigma}$.
  \item Comme précédemment, la clôture par anté-réduction est directe par la forme de la définition.
  \end{itemize}

  Ainsi, par induction, si $t\reduc u$ et $u\reali_\rho^\sigma \varphi$ alors $t\reali_\rho^\sigma\varphi$.
\end{proof}

\subsubsection{Système de types}

On définit un système de typage pour $\Lambda$, dont les types sont des propositions.

\begin{defi}[Typage]
  Nos contextes de typage de termes sont des listes de couples $(x : \varphi)\in\mathcal X_\Lambda\times \Propo$. On définit la relation de typage par les règles suivantes, où les deux premiers contextes servent à typer les variables du premier et second ordre (en particulier on considère que tous les séquents sont bien typés)~:
  \begin{center}
    \begin{prooftree}
      \infer0[Ax]{\Gamma\mid\Delta\mid\Xi,x : \varphi\vdash x : \varphi}
    \end{prooftree}

    \vspace{0.5cm}
    
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi \vdash t : \varphi}
      \infer1[Aff$_1$]{\Gamma, \bx : A\mid\Delta\mid\Xi \vdash t : \varphi}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash t : \varphi}
      \infer1[Aff$_2$]{\Gamma\mid\Delta, X : A_1,\ldots,A_n\mid\Xi\vdash t : \varphi}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash t : \varphi}
      \infer1[Aff$_\Lambda$]{\Gamma\mid\Delta\mid\Xi, x : \psi\vdash t : \varphi}
    \end{prooftree}

    \vspace{0.5cm}
    
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi, x : \varphi \vdash t : \psi}
      \infer1[$\to_\mathrm i$]{\Gamma\mid\Delta\mid\Xi\vdash \lambda x.t : \varphi \to \psi}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash t : \varphi \to \psi}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash u : \varphi}
      \infer2[$\to_\mathrm e$]{\Gamma\mid\Delta\mid\Xi\vdash t\:u : \psi}
    \end{prooftree}

    \vspace{0.5cm}
    
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash t : \varphi}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash u : \psi}
      \infer2[$\land_\mathrm i$]{\Gamma\mid\Delta\mid\Xi\vdash \langle t,u\rangle : \varphi\land \psi}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash t : \varphi_1\land\varphi_2}
      \infer1[$\land_\mathrm e^i$]{\Gamma\mid\Delta\mid\Xi\vdash \pi_i\;t : \varphi_i}
    \end{prooftree}

    \vspace{0.5cm}

    \begin{prooftree}
      \hypo{\Gamma, \bx : A\mid\Delta\mid\Xi\vdash t : \varphi}
      \infer1[$\forall^1_\mathrm i$]{\Gamma\mid\Delta\mid\Xi\vdash t : \forall \bx^A, \varphi}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash t : \forall \bx^A, \varphi}
      \hypo{\Gamma\vdash \bt : A}
      \infer2[$\forall^1_\mathrm e$]{\Gamma\mid\Delta\mid\Xi\vdash t : \varphi[\bt/\bx]}
    \end{prooftree}

    \vspace{0.5cm}
    
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta, X^{A_1,\ldots,A_n}\mid\Xi\vdash t : \varphi}
      \infer1[$\forall^2_\mathrm i$]{\Gamma\mid\Delta\mid\Xi\vdash t : \forall X^{A_1,\ldots,A_n}, \varphi}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash t : \forall X^{A_1,\ldots,A_n}, \varphi}
      \hypo{\Gamma, \bx_1 : A_1,\ldots,\bx_n : A_n\mid\Delta\vdash \psi : \Propo}
      \infer2[$\forall^2_\mathrm e$]{\Gamma\mid\Delta\mid\Xi\vdash t : \varphi[\psi/X]}
    \end{prooftree}

    \vspace{0.5cm}

    \begin{prooftree}
      \infer0[$\bN_0$]{\Gamma\mid\Delta\mid\Xi\vdash \bZ : \bN(0)}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash t : \bN(\bt)}
      \infer1[$\bN_S$]{\Gamma\mid\Delta\mid\Xi\vdash \bfS\;t : \bN(S\:\bt)}
    \end{prooftree}

    \vspace{0.5cm}
    
    \begin{prooftree}
      \infer0[$\bB_{\btt}$]{\Gamma\mid\Delta\mid\Xi\vdash \btt : \bB(\btt)}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \infer0[$\bB_{\bff}$]{\Gamma\mid\Delta\mid\Xi\vdash \bff : \bB(\bff)}
    \end{prooftree}

    \vspace{0.5cm}
    
    \begin{prooftree}
      \infer0[$\bL_{[\;]}$]{\Gamma\mid\Delta\mid\Xi\vdash [\:] : \bL([\:])}
    \end{prooftree}
    \quad
    \begin{prooftree}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash t : \bN(\bt)}
      \hypo{\Gamma\mid\Delta\mid\Xi\vdash u : \bL(\bu)}
      \infer2[$\bL_{::}$]{\Gamma\mid\Delta\mid\Xi\vdash t :: u : \bL(\bt :: \bu)}
    \end{prooftree}
  \end{center}
\end{defi}

On définit une notion de valuation adaptée au lemme d'adéquation.

\begin{defi}[Valuation de réalisabilité]
  Soit un contexte de typage du premire ordre $\Gamma$, un contexte de typage du second ordre $\Delta$ et un contexte de typage de termes $\Xi = (x_i : \varphi_i)_{i\in I}$. On dit que des valuations $\sigma, \rho, \nu$ où $\nu : \mathcal X_\Lambda \to \Lambda$ sont adéquates pour $\Gamma,\Delta,\Xi$, ce que l'on note $\nu\reali_\rho^\sigma \Gamma,\Delta,\Xi$, si $\sigma$ est adéquate pour $\Gamma$, $\rho$ est adéquate pour $\Delta$ et si
  \[\forall i \in I, \sigma(x_i)\reali_\rho^\sigma\varphi_i\]
\end{defi}

On définit aussi la substitution simultanée $t^\nu$ en remplaçant directement chaque variable libre $x$ de $t$ par $\nu(x)$ dans $t$.

On a besoin de deux lemmes de substitutions, pour le premier et le second ordre.

\begin{lem}
  Pour tous $\sigma,\rho$, $\bt : A$, $t\in\Lambda$, $\varphi : \Propo$, on a
  \[t\reali_\rho^{\sigma[\bx \leftarrow \bt^\sigma]} \varphi\iff t\reali_\rho^\sigma \varphi[\bt/\bx]\]
\end{lem}

\begin{proof}
  On remarque que chaque apparition d'un terme $\bt$ dans une formule $\varphi$ est remplacée par $\bt^\sigma$ lors de son interprétation. De plus, pour un terme $\bu$, $\bu^{\sigma[x\leftarrow \bt^\sigma]} = (\bu[\bt/x])^\sigma$. Formellement, ces deux arguments demandent une induction (respectivement sur $\varphi$ et sur $\bu$).
\end{proof}

\begin{lem}
  Pour tous $\Gamma,\Delta$, si $\Gamma\mid\Delta\vdash \psi : \Propo$ alors pour tous $\rho,\sigma$ on a, en notant $S : (a_1,\ldots,a_n) \mapsto \trad\psi_\rho^{\sigma[\bx_1\leftarrow a_1,\ldots,\bx_n\leftarrow a_n]}$~:
  \[t\reali_{\rho[X\leftarrow S]}^\sigma \varphi \iff t\reali_\rho^\sigma \varphi[\psi/X]\]
\end{lem}

\begin{proof}
  Par induction sur $\varphi$~:
  \begin{itemize}
  \item si $\varphi = X(\bt_1,\ldots,\bt_n)$, alors $\trad\varphi_{\rho[X\leftarrow S]}^\sigma = S(\bt_1^\sigma,\ldots,\bt_n^\sigma) = \trad\psi_\rho^{\sigma[\bx_1\leftarrow \bt_1^\sigma,\ldots,\bx_n\leftarrow \bt_n^\sigma]} = $ A FAIRE
  \item A FAIRE
  \end{itemize}
\end{proof}

\begin{lem}[Adéquation]
  Soient des contextes $\Gamma,\Delta,\Xi$ et des valuations $\nu\reali_\rho^\sigma \Gamma,\Delta,\Xi$. Soit $t\in\Lambda$ et $\varphi\in\Propo$ tels que $\Gamma\mid\Delta\mid\Xi\vdash t : \varphi$. Alors $t^\nu \reali_\rho^\sigma \varphi$.
\end{lem}

\begin{proof}
  La preuve se fait par induction sur la relation de typage $\vdash$~:
  \begin{itemize}
  \item Pour le cas d'une variable, il est clair que si $\varphi = \varphi_i$ et $x = x_i$ alors $t^\nu = \nu(x_i)\reali_\rho^\sigma \varphi_i$.
  \item Supposons que pour tout $\nu \reali_\rho^\sigma \Gamma,\Delta,(\Xi, x : \varphi)$, on a $t^\nu \reali_\rho^\sigma \psi$. Soit $\nu \reali_\rho^\sigma \Gamma,\Delta,\Xi$, montrons que $(\lambda x.t)^\nu\reali_\rho^\sigma \varphi \to \psi$. Soit $u \reali_\rho^\sigma \varphi$, alors $t^{\nu[x \leftarrow u]}\reali_\rho^\sigma \psi$ puisque $\nu[x\leftarrow u]\reali_\rho^\sigma \Gamma,\Delta,(\Xi, x : \psi)$. De plus, quitte à renommer, on a $t^{\nu[x\leftarrow u]} = t^\nu[u/x]$ donc $t^\nu[u/x]\reali_\rho^\sigma \psi$, donc par saturation $(\lambda x.t^\nu) u \reali_\rho^\sigma \psi$, donc $\lambda x.t^\nu\reali_\rho^\sigma \varphi\to\psi$.
  \item Supposons que $t^\nu\reali_\rho^\sigma \varphi \to \psi$ et $u^\nu\reali_\rho^\sigma \varphi$, alors par définition $(t\;u)^\nu\reali_\rho^\sigma \psi$.
  \item Supposons que $t^\nu\reali_\rho^\sigma \varphi$ et $u^\nu\reali_\rho^\sigma \psi$, alors $\pi_1\;\langle t,u\rangle^\nu \reduc t^\nu \reali_\rho^\sigma \varphi$ et $\pi_2\;\langle t,u\rangle^\nu\reduc u^\nu \reali_\rho^\sigma \psi$, donc $\langle t,u\rangle^\nu \reali_\rho^\sigma \varphi\land\psi$.
  \item Si $t^\nu \reali_\rho^\sigma \varphi_1\land\varphi_2$ alors par définition, $\pi_i\;t^\nu\reali_\rho^\sigma \varphi_i$.
  \item On suppose que pour tout $\nu\reali_\rho^\sigma (\Gamma, \bx : A), \Delta,\Xi$, $t^\nu\reali_\rho^\sigma \varphi$. Soit alors des valuations $\nu\reali_\rho^\sigma \Gamma,\Delta,\Xi$, alors par hypothèse pour tout $a \in \mathbb A$, $\nu\reali_\rho^{\sigma[\bx\leftarrow a]}(\Gamma, \bx : A), \Delta, \Xi$ donc $t^\nu\reali_\rho^{\sigma[\bx \leftarrow a]}\varphi$ pour tout $a\in \mathbb A$, ce qui signifie que $t^\nu \reali_\rho^\sigma \forall \bx^A, \varphi$.
  \item On suppose que $t^\nu\reali_\rho^\sigma \forall \bx, \varphi$, donc pour tout $\bt : A$, $\bt^\sigma \in \mathbb A$ donc $t^\nu\reali_{\rho[\bx\leftarrow \bt^\sigma]}^\sigma \varphi$, c'est-à-dire $t^\nu\reali_\rho^\sigma \varphi[\bt/\bx]$ par le lemme de substitution du premier ordre.
  \item On suppose que pour tout $\nu\reali_\rho^\sigma \Gamma, (\Delta, X : A_1,\ldots,A_n), \Xi$, $t^\nu \reali_\rho^\sigma \varphi$. Soit alors des valuations $\nu\reali_\rho^\sigma\Gamma, \Delta,\Xi$. On voit que pour tout $S : A_1\times\ldots\times A_n \to \SAT$, $\nu\reali_{\rho[X\leftarrow S]}^\sigma \Gamma, (\Delta, X : A_1,\ldots,A_n),\Xi$ donc $t^\nu\reali_{\rho[X\leftarrow S]}^\sigma \varphi$. Comme cela tient pour tout $S : A_1\times\ldots\times A_n \to \SAT$, on en déduit que $t^\nu\reali_\rho^\sigma \forall X, \varphi$.
  \item Si $t^\nu\reali_\rho^\sigma \forall X, \varphi$ et $\Gamma,x_1 : A_1,\ldots,x_n : A_n\mid\Delta\vdash \psi : \Propo$, alors en particulier $S : (a_1,\ldots,a_n) \mapsto \trad\psi_\rho^{\sigma[x_1\leftarrow a_1,\ldots, x_n \leftarrow a_n]}$ définit une fonction $A_1\times\ldots\times A_n \to\SAT$, donc $t^\nu\reali_{\rho[X\leftarrow S]}^\sigma \varphi$, c'est-à-dire $t^\nu\reali_\rho^\sigma \varphi[\psi/X]$ par le lemme de substitution du second ordre.
  \item On voit que $\bZ\reduc^*\bZ$ donc $\bZ^\nu\reali_\rho^\sigma\bN(0)$.
  \item Si $t^\nu\reali_\rho^\sigma \bN(\bt)$ alors $t^\nu\reduc^*\overline{\bt^\sigma}$ donc $\bfS\;t^\nu\reduc^* \overline{S\:\bt^\sigma}$, donc $\bfS\;t^\nu\reali_\rho^\sigma \bN(S\;\bt)$.
  \item Comme $\btt\reduc^* \btt$, on en déduit que $\btt^\nu\reali_\rho^\sigma\bB(\btt)$.
  \item Comme $\bff\reduc^* \bff$, on en déduit que $\btt^\nu\reali_\rho^\sigma\bB(\bff)$.
  \item Pareil pour les listes.
  \end{itemize}

  On en déduit par induction le résultat.
\end{proof}

En particulier, si $\vdash t : \varphi$ alors $t\reali \varphi$.

\subsubsection{Quelques réaliseurs élémentaires}

On commence par donner quelques réaliseurs simples pour donner l'idée de comment prouver des résultats sur notre modèle de réalisabilité.

\begin{expl}
  Pour toute sorte $A$, $\lambda x.x\reali \forall \bx^A, \bx = \bx$. On peut directement le déduire de l'adéquation~:
  \begin{center}
    \begin{prooftree}
      \infer0[Ax]{\bx : A\mid X^A\mid x : X(\bx)\vdash x : X(\bx)}
      \infer1[$\to_\mathrm i$]{\bx : A\mid X^A\mid\varnothing\vdash \lambda x.x : X(\bx) \to X(\bx)}
      \infer1[$\forall^2_\mathrm i$]{\bx : A\mid\varnothing\mid\varnothing\vdash \lambda x.x : \bx = \bx}
      \infer1[$\forall^1_\mathrm i$]{\vdash \lambda x.x : \forall \bx^A, \bx = \bx}
    \end{prooftree}
  \end{center}
\end{expl}

\begin{expl}
  On peut réaliser la récurrence relativisée définie comme la formule suivante~:
  \[R \defeq \forall X^\bN, X(0) \implies (\forall n^{\{\bN\}}, X(n) \implies X(S\;n))\implies \forall n^{\{\bN\}}, X(n)\]

  Ceci se réalise directement par $\rec_\bN$ (à lire comme $\lambda t\;u\;v.\rec_\bN\;t\;u\;v$). Pour prouver que $\rec_\bN\reali R$, on ne peut pas utiliser l'adéquation puisqu'il n'y a pas de règle de typage pour $\rec_\bN$. Soit donc une fonction $F : \bN \to \SAT$, $t\reali X(0)$, $u\reali \forall n^{\{\bN\}}, X(n) \implies X(S\;n)$ et $v\reali \bN(n)$. On sait donc que $v\reduc^* \overline n$. On peut donc raisonner par induction sur ce $n$~:
  \begin{itemize}
  \item si $v\reduc^* \bZ$, alors
    \[\rec_\bN\;t\;u\;v\reduc^* \rec_\bN\;t\;u\;\bZ\reduc t\reali X(0)\]
    donc $\rec_\bN\;t\;u\;v\reali X(0)$ par saturation.
  \item supposons que pour tout $v\reduc^* \overline n$, $\rec_\bN\;t\;u\;v\reali X(n)$, et soit $v\reduc^* S\;\overline n$, alors
    \[\rec_\bN\;t\;u\;v \reduc^* \rec_\bN\;t\;u\;(S\;\overline n)\reduc u\;\overline n\;(\rec_\bN\;t\;u\;\overline n)\]
    or $u\reali \forall n^{\{\bN\}}, X(n)\implies X(S\;n)$ donc $u\;\overline n\reali X(n)\implies X(S\;n)$. De plus, par hypothèse d'induction, $\rec_\bN\;t\;u\;\overline n \reali X(n)$, donc $u\;\overline n\;(\rec_\bN\;t\;u\;\overline n)\reali X(S\;n)$. Donc par saturation $\rec_\bN\;t\;u\;v\reali X(S\;n)$.
  \end{itemize}
  Ainsi, par induction, pour tout $n\in \bN$, si $v\reduc^* \overline n$ alors $\rec_\bN\;t\;u\;v\reali X(n)$, ce qui signifie donc que $\rec_\bN\;t\;u\reali \forall x^{\{\bN\}}, X(n)$, donc que $\rec_\bN\reali R$.
\end{expl}

\begin{expl}
  On peut construire un test d'égalité des entiers~:
  \[t_= \defeq \rec_\bN\;(\rec_\bN\;\btt\;(\lambda\_\;\_.\bff))\;(\lambda p.\lambda f.\rec_\bN\;\bff\;(\lambda q\;\_. f\;q))\reali\Dec(=^{\bN,\bN})\]
  On montre par induction sur $(n,m)$ que $t_=$ réduit vers la valeur attendue à chaque fois~:
  \begin{itemize}
  \item si $(n,m) = (0,0)$, on a
    \[t_=\;\bZ\;\bZ \reduc \rec_\bN\;\btt\;(\lambda \_\;\_.\bff)\;\bZ\reduc \btt\]
  \item si $(n,m) = (0,S\;p)$, on a
    \[t_=\;\bZ\;(\bfS\;\overline p)\reduc \rec_\bN\;\btt\;(\lambda\_\;\_.\bff)\;(\bfS\;\overline p)\reduc (\lambda\_\;\_.\bff)\;\overline p\;(\rec_\bN\;\btt\;(\lambda\_\;\_.\bff)\;\overline p) \reduc^2 \bff\]
  \item si $(n,m) = (S\;p,0)$, on a
    \[t_=\;(\bfS\;\overline p)\;\bZ\reduc (\lambda p.\lambda f.\rec_\bN\;\bff\;(\lambda q\;\_.f\;q))\;\overline p\;(t_=\;\overline p)\;\bZ\reduc^2 \rec_\bN\;\bff\;(\lambda q\;\_.(t_=\;\overline p)\;q)\;\bZ \reduc \bff\]
  \item si $(n,m) = (S\;p,S\;q)$, on a
    \begin{align*}
      t_=\;(\bfS\;\overline p)\;(\bfS\;\overline q)&\reduc (\lambda p.\lambda f.\rec_\bN\;\bff\;(\lambda q\;\_.f\;q))\;\overline p\;(t_=\;\overline p)\;(\bfS\;\overline q)\\
      &\reduc^2 \rec_\bN\;\bff\;(\lambda q\;\_.(t_=\;\overline p)\;q)\;(\bfS\;\overline q)\\
      &\reduc (\lambda q\;\_.t_=\;\overline p\;q)\;\overline q\;(\rec_\bN\;\bff\;(\lambda q\;\_.(t_=\;\overline p)\;q)\;\overline q)\\
      &\reduc^2 t_=\;\overline p\;\overline q
    \end{align*}
    et l'hypothèse d'induction nous dit que $t_=\;\overline p\;\overline q$ se réduit vers $\btt$ si les deux termes sont égaux, vers $\bff$ s'ils sont différents.
  \end{itemize}
  Ainsi $t_=\reali \Dec(=^{\bN,\bN})$.
\end{expl}

\subsubsection{Traiter les arbres}

On s'intéresse maintenant au cas des arbres. Dans le contexte des types, on peut naturellement considérer qu'un arbre est un type généré par une constante et un opérateur prenant une fonction partielle $\bN \to \mathrm{Tree}$ pour retourner un nouvel arbre. Ainsi un n\oe ud construit à partir d'une fonction $f$ est un n\oe ud dont la $i$-ème branche mène à $f(n)$. Cela nous donne une construction proche de celle des $W$-types de Martin-Löf. Cependant, comme notre cadre est entre la programmation et les mathématiques à rebours, nous adoptons un formalisme plus extrinsèque, en considérant des prédicats sur $\bL$.

On a alors besoin de définir différentes primitives pour traiter les prédicats sur $\bL$.

\begin{defi}[Préfixe]
  On définit un nouveau symbole de relation, $\preceq$, d'arité $\bL,\bL$. Ainsi $\ell \preceq \ell'$ est une nouvelle proposition atomique. On étend alors notre interprétation de réalisabilité~:
  \[\trad{\ell \preceq \ell'}_\rho^\sigma \defeq
  \left\{\begin{array}{l}
  \Lambda\text{ si } \ell \text{ est un préfixe de } \ell'\\
  \varnothing\text{ sinon}
  \end{array}\right.\]
\end{defi}

\begin{lem}
  $\preceq$ est décidable. En effet, on peut construire un réaliseur de $\Dec(\preceq^{\bL,\bL})$~:
  \[\rec_\bL\;(\lambda x.\btt)\;[\cdots]\reali \Dec(\preceq^{\bL,\bL})\]
\end{lem}

\begin{defi}[Arbre]
  Un arbre est un prédicat sur $\bL$ clos par préfixe~:
  \[\isTree(T) \defeq \forall \bx^\bL\;\by^\bL, (\bx\preceq \by \implies T(\by) \implies T(\bx))\]
\end{defi}

\begin{nota}
  Pour alléger l'introduction des arbres, on prendra ces conventions d'écritures~:
  \[\forall T^\Tree, \varphi \defeq \forall T^\bL, \isTree(T) \implies \varphi\qquad \forall T^{\{\Tree\}}, \varphi\defeq \forall T^{\{\bL\}}, \isTree(T) \implies \varphi\]
\end{nota}

On définit de plus le prédicat disant d'un arbre qu'il est binaire. Celui-ci nous permettra d'introduire des affaiblissement du lemme de König.

\begin{defi}[Arbre binaire]
  On dit qu'un arbre $T$ est binaire s'il pour tout $u\in T$, on ne peut pas augmenter $u$ avec un nombre autre que $0$ ou $1$~:
  \[\isBinTree(T) \defeq \forall \ell^\bL, T(\ell) \implies (T(\bZ :: \ell) \implies \bot) \land (T(\boldsymbol 1 :: \ell) \implies \bot)\]
\end{defi}

\begin{nota}
  On prend des conventions similaires à celles pour $\Tree$~:
  \[\forall T^\BinTree, \varphi \defeq \forall T^\Tree, \isBinTree(T) \implies \varphi \qquad \forall T^{\{\BinTree\}}, \varphi \defeq \forall T^{\{\Tree\}}, \isBinTree(T) \implies \varphi\]
\end{nota}

Donnons alors la version faible du lemme de König~:

\[\WKL \defeq \forall T^\BinTree, (\forall n^{\{\bN\}}, \exists \ell^{\{\bL\}}, |\ell| = n \land T(\ell)) \implies \exists X^\bN, \forall n^{\{\bN\}}, T(X^\bN_{0,\ldots,n-1})\]

\end{document}
